import type { AudioGraphOptions, AudioNodeInit, ThrottleOptions, DenoiseWorkletNodeInit, AnalyzerNodeInit, AudioGraph } from '@pexip/media-processor';
import type { MediaDeviceRequest } from '@pexip/media-control';
import type { Process, Media, DenoiseParams, AudioContentHint } from './types';
type AudioNodeInits = AudioNodeInit[];
/**
 * A function to be called to create the AudioNodes needed for the graph
 * creation
 *
 * @param media - Media to be used for the AudioGraph creation
 */
type CreateNodes = (media: Media) => AudioNodeInits;
interface AudioProcessOptions {
    /**
     * An option is being passed to AnalyserNode creation when used
     * @see https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/fftSize
     *
     * @defaultValue 2048
     */
    fftSize?: number;
    /**
     * Params needed for setting up noise suppression WebAssembly and
     * AudioWorklet
     */
    denoiseParams?: DenoiseParams;
    /**
     * Update frequency for analyzer per second
     *
     * @defaultValue 0.5
     */
    analyzerUpdateFrequency?: number;
    /**
     * Audio Signal Detection duration in second
     *
     * @defaultValue 4.0
     */
    audioSignalDetectionDuration?: number;
    /**
     * Callback when Voice Activity detected
     */
    onVoiceActivityDetected?: () => void;
    /**
     * Callback when Audio Signal detected
     */
    onAudioSignalDetected?: (silent: boolean) => void;
    /**
     * @see AudioGraphOptions
     */
    audioGraphOptions?: AudioGraphOptions;
    /**
     * Whether or to enable this processor
     */
    shouldEnable: () => boolean;
    /**
     * Insert additional nodes between the source and destination
     */
    createNodes?: CreateNodes;
    /**
     * Silent threshold, how large the value of the sample is considered as
     * silent in FFTed time domain
     */
    silentThreshold?: number;
    scope?: string;
}
interface AudioStreamProcessorProps {
    audioGraphOptions?: AudioGraphOptions;
    denoiseWasm?: ArrayBuffer;
    vad?: boolean;
    asd?: boolean;
    denoise?: boolean;
    analyzerBuffer?: Float32Array;
    denoiseNode?: DenoiseWorkletNodeInit;
    additionalAudioSourceNode?: AudioNodeInit<MediaStreamAudioSourceNode, MediaStreamAudioSourceNode>;
    mixerNode?: AudioNodeInit<ChannelMergerNode, ChannelMergerNode>;
    analyzer?: AnalyzerNodeInit;
    contentHint?: AudioContentHint;
    audioGraph?: AudioGraph;
}
declare const FEATURE_KEYS: ['denoise', 'vad', 'asd', 'contentHint'];
type FeaturePropKeys = (typeof FEATURE_KEYS)[number];
type FeatureProps = Pick<AudioStreamProcessorProps, FeaturePropKeys>;
export declare const updateFeatureProps: (constraints: MediaDeviceRequest['audio'], props: FeatureProps) => FeatureProps;
/**
 * Create a Audio Stream Processor and will own the stream passed-in
 */
export declare const createAudioStreamProcess: ({ analyzerUpdateFrequency, audioGraphOptions, audioSignalDetectionDuration, clock, createNodes, denoiseParams, fftSize, onAudioSignalDetected, onVoiceActivityDetected, shouldEnable, silentThreshold, throttleMs, scope, }: AudioProcessOptions & ThrottleOptions) => Process<Promise<Media>>;
export {};
