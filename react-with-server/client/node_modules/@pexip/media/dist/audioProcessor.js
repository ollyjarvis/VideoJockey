import { stopMediaStream, extractConstraintsWithKeys, muteStreamTrack, } from '@pexip/media-control';
import { createQueue, isEmpty } from '@pexip/utils';
import { createAudioGraph, createAudioGraphProxy, createStreamSourceGraphNode, createStreamDestinationGraphNode, createAnalyzerSubscribableGraphNode, createDenoiseWorkletGraphNode, createAudioSignalDetector, createVADetector, createVoiceDetectorFromTimeData, createVoiceDetectorFromProbability, avg, } from '@pexip/media-processor';
import { logger } from './logger';
import { isAudioContentHint } from './typeGuard';
import { shallowCopy, wrapToJSON, applyExtendedConstraints } from './utils';
/**
 * Fetch the wasm when it doesn't exist from the provided, otherwise do nothing
 *
 * @param denoiseWasm - The wasm if it exists
 * @param wasmURL - The URL for the fetching
 */
const fetchDenoiseWasm = async (denoiseWasm, wasmURL) => {
    if (!wasmURL || denoiseWasm) {
        return denoiseWasm;
    }
    return await (await fetch(wasmURL)).arrayBuffer();
};
const FEATURE_KEYS = [
    'denoise',
    'vad',
    'asd',
    'contentHint',
];
const getAudioConstraints = extractConstraintsWithKeys(FEATURE_KEYS);
export const updateFeatureProps = (constraints, props) => {
    const extracted = getAudioConstraints(constraints);
    return FEATURE_KEYS.reduce((accm, key) => {
        switch (key) {
            case 'contentHint': {
                const [[feature] = []] = extracted[key];
                if (isAudioContentHint(feature) && props[key] !== feature) {
                    props[key] = feature;
                    return { ...accm, [key]: feature };
                }
                return accm;
            }
            case 'denoise':
            case 'asd':
            case 'vad': {
                const [feature] = extracted[key];
                if (feature !== undefined && props[key] !== feature) {
                    props[key] = feature;
                    return { ...accm, [key]: feature };
                }
                return accm;
            }
            default:
                return accm;
        }
    }, {});
};
/**
 * Create a Audio Stream Processor and will own the stream passed-in
 */
export const createAudioStreamProcess = ({ analyzerUpdateFrequency = 0.5, // 0.5 Hz
audioGraphOptions, audioSignalDetectionDuration = 4.0, // 4 seconds
clock, createNodes, denoiseParams, fftSize = 2048, // FFT size
onAudioSignalDetected, onVoiceActivityDetected, shouldEnable, silentThreshold = 10.0 / 32767, // At least one LSB 16-bit data (compare is on absolute value).
throttleMs = 3000, // 3 seconds
scope = 'media', }) => {
    const props = {
        audioGraphOptions,
        vad: false,
        asd: false,
        denoise: false,
    };
    const detectAudio = onAudioSignalDetected &&
        createAudioSignalDetector(() => !!props.asd, onAudioSignalDetected);
    const detectVA = onVoiceActivityDetected &&
        createVADetector(onVoiceActivityDetected, () => !!props.vad, {
            throttleMs,
            clock,
        });
    const detectVAFromTimeData = detectVA?.(createVoiceDetectorFromTimeData());
    const createDenoiseNode = async (denoise) => {
        if (!denoise) {
            return undefined;
        }
        if (props.denoiseNode) {
            return props.denoiseNode;
        }
        if (denoiseParams?.workletModule) {
            try {
                await props.audioGraph?.addWorklet(denoiseParams?.workletModule, denoiseParams?.workletOptions);
            }
            catch (error) {
                logger.error({
                    scope,
                    error,
                    moduleURL: denoiseParams?.workletModule,
                    options: denoiseParams?.workletOptions,
                }, 'Failed add worklet');
                return undefined;
            }
        }
        try {
            props.denoiseWasm = await fetchDenoiseWasm(props.denoiseWasm, denoiseParams?.wasmURL);
        }
        catch (error) {
            logger.error({
                scope,
                error,
                url: denoiseParams?.wasmURL,
                prevWasm: props.denoiseWasm,
            }, 'Failed to fetch denoise wasm');
            return undefined;
        }
        const detectVAFromProbability = detectVA?.(createVoiceDetectorFromProbability());
        if (props.denoiseWasm) {
            const denoise = createDenoiseWorkletGraphNode(props.denoiseWasm, vads => {
                detectVAFromProbability?.(avg(vads));
            });
            props.denoiseNode = denoise;
            return denoise;
        }
    };
    const createAnalyzer = () => {
        const shouldUseAnalyzer = () => !!((props.vad && !props.denoise) || props.asd) &&
            (detectAudio || detectVA);
        if (!shouldUseAnalyzer()) {
            return;
        }
        if (props.analyzer) {
            return props.analyzer;
        }
        const detectSilentAudio = detectAudio?.(createQueue(audioSignalDetectionDuration / analyzerUpdateFrequency), silentThreshold);
        const analyzer = createAnalyzerSubscribableGraphNode({
            updateFrequency: analyzerUpdateFrequency,
            messageHandler: analyzer => {
                if (shouldUseAnalyzer()) {
                    if (!props.analyzerBuffer) {
                        // Only Create the buffer when needed
                        props.analyzerBuffer = new Float32Array(fftSize);
                    }
                    analyzer.getFloatTimeDomainData(props.analyzerBuffer);
                    const data = Array.from(props.analyzerBuffer);
                    detectSilentAudio?.(data);
                    !props.denoise && detectVAFromTimeData?.(data);
                }
            },
            fftSize,
        });
        props.analyzer = analyzer;
        return analyzer;
    };
    return async (mediaP) => {
        const media = await mediaP;
        updateFeatureProps(media.constraints?.audio, props);
        const shouldProcessAudio = shouldEnable() &&
            !!media.stream?.getAudioTracks().length &&
            (!!onVoiceActivityDetected ||
                !!onAudioSignalDetected ||
                props.asd ||
                props.vad ||
                props.denoise ||
                !!createNodes);
        if (!media.stream?.getAudioTracks().length || !shouldProcessAudio) {
            return media;
        }
        try {
            const source = createStreamSourceGraphNode(media.stream);
            const destination = createStreamDestinationGraphNode();
            const otherNodes = createNodes?.(media) ?? [];
            const analyzer = createAnalyzer();
            const initialAudioNodeConnection = [
                [source, ...otherNodes, destination],
                [source, analyzer],
            ];
            logger.debug({ initialAudioNodeConnection, scope }, 'Initial AudioNodeConnection');
            const audioGraph = createAudioGraphProxy(createAudioGraph(initialAudioNodeConnection, props.audioGraphOptions), {
                connect: (target, args) => {
                    logger.debug({ scope, target, args }, 'connect nodes');
                },
                disconnect: (target, args) => {
                    logger.debug({ scope, target, args }, 'disconnect nodes');
                },
            });
            props.audioGraph = audioGraph;
            const denoiseNode = await createDenoiseNode(props.denoise);
            const connectDenoise = (node) => {
                if (node) {
                    audioGraph.disconnect([source, ...otherNodes, destination]);
                    audioGraph.connect([
                        source,
                        node,
                        ...otherNodes,
                        destination,
                    ]);
                }
            };
            connectDenoise(denoiseNode);
            const tracks = [
                ...(destination?.node?.stream.getAudioTracks() ?? []),
                ...(media.stream?.getVideoTracks().map(t => t.clone()) ?? []),
            ];
            const stream = new MediaStream(tracks);
            const applyConstraints = applyExtendedConstraints(media, async (constraints) => {
                if (isEmpty(constraints.audio)) {
                    return;
                }
                const features = updateFeatureProps(constraints.audio, props);
                logger.debug({ scope, constraints: constraints.audio, features }, 'apply audio constraints');
                if (isEmpty(features) ||
                    ['closed', 'closing'].includes(audioGraph.state)) {
                    return;
                }
                try {
                    const denoiseNode = await createDenoiseNode(props.denoise);
                    if (denoiseNode) {
                        if (!source.hasConnectedTo(denoiseNode)) {
                            connectDenoise(denoiseNode);
                        }
                    }
                    else {
                        if (props.denoiseNode) {
                            audioGraph.disconnect([
                                source,
                                props.denoiseNode,
                                ...otherNodes,
                                destination,
                            ]);
                            audioGraph.connect([
                                source,
                                ...otherNodes,
                                destination,
                            ]);
                            audioGraph.releaseInit(props.denoiseNode);
                            props.denoiseNode = undefined;
                        }
                    }
                    const analyzer = createAnalyzer();
                    if (analyzer) {
                        audioGraph.connect([source, analyzer]);
                    }
                    else {
                        if (props.analyzer) {
                            audioGraph.disconnect([source, props.analyzer]);
                            audioGraph.releaseInit(props.analyzer);
                            props.analyzer = undefined;
                        }
                    }
                }
                catch (error) {
                    if (error instanceof Error) {
                        logger.error({
                            scope,
                            constraints: constraints.audio,
                            features,
                        }, 'failed to apply audio constraints');
                    }
                }
            });
            const release = async () => {
                logger.debug({ scope }, 'Release Media');
                stopMediaStream(stream);
                // Release Props
                await audioGraph.release();
                await media.release();
                props.denoiseNode = undefined;
                props.analyzer = undefined;
                props.audioGraph = undefined;
            };
            const muteAudio = (mute) => {
                media.muteAudio(mute);
                muteStreamTrack(stream)(mute, 'audio');
            };
            const muteVideo = (mute) => {
                media.muteVideo(mute);
                muteStreamTrack(stream)(mute, 'video');
            };
            const prevGetSettings = media.getSettings;
            return wrapToJSON(shallowCopy(media, {
                stream,
                applyConstraints,
                muteAudio,
                muteVideo,
                release,
                getSettings: () => {
                    const { audio, video } = prevGetSettings();
                    const denoise = !!props.denoiseNode &&
                        source.hasConnectedTo(props.denoiseNode);
                    const asd = !!props.asd;
                    const vad = !!props.vad;
                    const contentHint = stream.getAudioTracks().at(0)
                        ?.contentHint ?? '';
                    const audioSettings = {
                        denoise,
                        asd,
                        vad,
                        contentHint,
                    };
                    const settings = {
                        audio: audio.map(settings => ({
                            ...settings,
                            ...audioSettings,
                        })),
                        video,
                    };
                    logger.debug({ scope, settings: audioSettings }, 'get audio processor settings');
                    return settings;
                },
            }));
        }
        catch (error) {
            logger.error({ scope, error }, 'Unable to use WebAudio, return the raw media instead');
            return media;
        }
    };
};
